{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d92ecb8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:32.293702Z",
     "iopub.status.busy": "2025-04-24T16:29:32.293382Z",
     "iopub.status.idle": "2025-04-24T16:29:34.173682Z",
     "shell.execute_reply": "2025-04-24T16:29:34.172845Z"
    },
    "papermill": {
     "duration": 1.886938,
     "end_time": "2025-04-24T16:29:34.175361",
     "exception": false,
     "start_time": "2025-04-24T16:29:32.288423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweet-sentiment-classification-dataset/tweet_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23303d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:34.183536Z",
     "iopub.status.busy": "2025-04-24T16:29:34.183090Z",
     "iopub.status.idle": "2025-04-24T16:29:34.224434Z",
     "shell.execute_reply": "2025-04-24T16:29:34.223532Z"
    },
    "papermill": {
     "duration": 0.046965,
     "end_time": "2025-04-24T16:29:34.225801",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.178836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The event starts at 5 PM.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate how this turned out.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the worst thing ever!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>It’s cloudy outside.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Great job by the team!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I'm so happy about the news!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>It ruined my whole day.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I'm sick of this happening.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweet sentiment\n",
       "0        The event starts at 5 PM.   neutral\n",
       "1      I hate how this turned out.  negative\n",
       "2            Fantastic experience!  positive\n",
       "3            Fantastic experience!  positive\n",
       "4    This is the worst thing ever!  negative\n",
       "..                             ...       ...\n",
       "995           It’s cloudy outside.   neutral\n",
       "996         Great job by the team!  positive\n",
       "997   I'm so happy about the news!  positive\n",
       "998        It ruined my whole day.  negative\n",
       "999    I'm sick of this happening.  negative\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/tweet-sentiment-classification-dataset/tweet_sentiment.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5182302d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:34.234028Z",
     "iopub.status.busy": "2025-04-24T16:29:34.233443Z",
     "iopub.status.idle": "2025-04-24T16:29:34.256936Z",
     "shell.execute_reply": "2025-04-24T16:29:34.256021Z"
    },
    "papermill": {
     "duration": 0.029138,
     "end_time": "2025-04-24T16:29:34.258338",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.229200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      1000 non-null   object\n",
      " 1   sentiment  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4ba4267",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:34.266558Z",
     "iopub.status.busy": "2025-04-24T16:29:34.266216Z",
     "iopub.status.idle": "2025-04-24T16:29:34.272624Z",
     "shell.execute_reply": "2025-04-24T16:29:34.271639Z"
    },
    "papermill": {
     "duration": 0.012072,
     "end_time": "2025-04-24T16:29:34.273971",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.261899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chars\n",
      " !'.5AFGIJMPRSTWabcdefghijklmnoprstuvwxy’\n",
      "\n",
      "Toatl unique charactes: 41\n"
     ]
    }
   ],
   "source": [
    "# all unique chars that occure in the tweet\n",
    "all_text = ''.join(df['tweet'].astype(str))\n",
    "chars = sorted(set(all_text))\n",
    "print(\"Unique Chars\")\n",
    "print(''.join(chars))\n",
    "print('\\nToatl unique charactes:',len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba661bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:34.281868Z",
     "iopub.status.busy": "2025-04-24T16:29:34.281607Z",
     "iopub.status.idle": "2025-04-24T16:29:34.287887Z",
     "shell.execute_reply": "2025-04-24T16:29:34.286937Z"
    },
    "papermill": {
     "duration": 0.011699,
     "end_time": "2025-04-24T16:29:34.289174",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.277475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 32, 20, 16, 34, 0, 25, 30, 17, 0, 17, 39, 0, 34, 23, 20, 0, 34, 20, 16, 28, 1]\n",
      "Great job by the team!\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from chars to integere\n",
    "map1 = { ch:i for i,ch in enumerate(chars) }\n",
    "map2 = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [map1[c] for c in s]# encoder: take a string, output a list of integers.\n",
    "decode = lambda l: ''.join([map2[i] for i in l])# decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"Great job by the team!\"))\n",
    "print(decode(encode(\"Great job by the team!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54736b0d",
   "metadata": {
    "papermill": {
     "duration": 0.003143,
     "end_time": "2025-04-24T16:29:34.297081",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.293938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Let's now encode the entire text dataset and store it into a torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bd3edfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:34.305358Z",
     "iopub.status.busy": "2025-04-24T16:29:34.304968Z",
     "iopub.status.idle": "2025-04-24T16:29:39.102099Z",
     "shell.execute_reply": "2025-04-24T16:29:39.100964Z"
    },
    "papermill": {
     "duration": 4.803194,
     "end_time": "2025-04-24T16:29:39.103708",
     "exception": false,
     "start_time": "2025-04-24T16:29:34.300514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24608]) torch.int64\n",
      "tensor([14, 23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16,\n",
      "        34,  0,  4,  0, 11, 10,  3,  8,  0, 23, 16, 34, 20,  0, 23, 30, 37,  0,\n",
      "        34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35, 34,  3,  6, 16,\n",
      "        29, 34, 16, 33, 34, 24, 18,  0, 20, 38, 31, 20, 32, 24, 20, 29, 18, 20,\n",
      "         1,  6, 16, 29, 34, 16, 33, 34, 24, 18,  0, 20, 38, 31, 20, 32, 24, 20,\n",
      "        29, 18, 20,  1, 14, 23, 24, 33,  0, 24, 33,  0, 34, 23, 20,  0, 37, 30,\n",
      "        32, 33, 34,  0, 34, 23, 24, 29, 22,  0, 20, 36, 20, 32,  1, 14, 23, 20,\n",
      "         0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16, 34,  0,  4,\n",
      "         0, 11, 10,  3, 15, 23, 16, 34,  0, 16,  0, 37, 30, 29, 19, 20, 32, 21,\n",
      "        35, 27,  0, 19, 16, 39,  1,  7, 32, 20, 16, 34,  0, 25, 30, 17,  0, 17,\n",
      "        39,  0, 34, 23, 20,  0, 34, 20, 16, 28,  1, 15, 23, 16, 34,  0, 16,  0,\n",
      "        37, 30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16, 39,  1,  8, 34,  0, 32,\n",
      "        35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30, 27, 20,  0, 19, 16, 39,\n",
      "         3,  9, 35, 33, 34,  0, 21, 24, 29, 24, 33, 23, 20, 19,  0, 32, 20, 16,\n",
      "        19, 24, 29, 22,  0, 34, 23, 20,  0, 16, 32, 34, 24, 18, 27, 20,  3, 14,\n",
      "        30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,  3, 14, 23,\n",
      "        24, 33,  0, 24, 33,  0, 34, 23, 20,  0, 37, 30, 32, 33, 34,  0, 34, 23,\n",
      "        24, 29, 22,  0, 20, 36, 20, 32,  1,  8,  0, 23, 16, 34, 20,  0, 23, 30,\n",
      "        37,  0, 34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35, 34,  3,\n",
      "        14, 30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,  3, 15,\n",
      "        23, 16, 34,  0, 16,  0, 37, 30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16,\n",
      "        39,  1, 12, 20, 16, 27, 27, 39,  0, 19, 24, 33, 16, 31, 31, 30, 24, 29,\n",
      "        34, 20, 19,  0, 24, 29,  0, 34, 23, 20,  0, 32, 20, 33, 35, 27, 34, 33,\n",
      "         3,  8,  2, 28,  0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35,\n",
      "        34,  0, 34, 23, 20,  0, 29, 20, 37, 33,  1, 14, 23, 24, 33,  0, 35, 31,\n",
      "        19, 16, 34, 20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1, 14,\n",
      "        23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16, 34,\n",
      "         0,  4,  0, 11, 10,  3,  8,  2, 28,  0, 33, 24, 18, 26,  0, 30, 21,  0,\n",
      "        34, 23, 24, 33,  0, 23, 16, 31, 31, 20, 29, 24, 29, 22,  3,  8,  2, 28,\n",
      "         0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35, 34,  0, 34, 23,\n",
      "        20,  0, 29, 20, 37, 33,  1, 14, 23, 24, 33,  0, 35, 31, 19, 16, 34, 20,\n",
      "         0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1,  8,  2, 28,  0, 33,\n",
      "        24, 18, 26,  0, 30, 21,  0, 34, 23, 24, 33,  0, 23, 16, 31, 31, 20, 29,\n",
      "        24, 29, 22,  3, 12, 20, 16, 27, 27, 39,  0, 19, 24, 33, 16, 31, 31, 30,\n",
      "        24, 29, 34, 20, 19,  0, 24, 29,  0, 34, 23, 20,  0, 32, 20, 33, 35, 27,\n",
      "        34, 33,  3, 14, 23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34,\n",
      "        33,  0, 16, 34,  0,  4,  0, 11, 10,  3, 15, 23, 16, 34,  0, 16,  0, 37,\n",
      "        30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16, 39,  1, 14, 23, 24, 33,  0,\n",
      "        24, 33,  0, 34, 23, 20,  0, 37, 30, 32, 33, 34,  0, 34, 23, 24, 29, 22,\n",
      "         0, 20, 36, 20, 32,  1, 14, 23, 24, 33,  0, 24, 33,  0, 34, 23, 20,  0,\n",
      "        37, 30, 32, 33, 34,  0, 34, 23, 24, 29, 22,  0, 20, 36, 20, 32,  1,  8,\n",
      "         2, 28,  0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35, 34,  0,\n",
      "        34, 23, 20,  0, 29, 20, 37, 33,  1, 14, 30, 19, 16, 39,  0, 24, 33,  0,\n",
      "        14, 35, 20, 33, 19, 16, 39,  3, 14, 23, 24, 33,  0, 35, 31, 19, 16, 34,\n",
      "        20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1, 14, 23, 24, 33,\n",
      "         0, 35, 31, 19, 16, 34, 20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16,\n",
      "        39,  1,  8, 34,  0, 32, 35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30,\n",
      "        27, 20,  0, 19, 16, 39,  3,  8, 34, 40, 33,  0, 18, 27, 30, 35, 19, 39,\n",
      "         0, 30, 35, 34, 33, 24, 19, 20,  3,  8, 34, 40, 33,  0, 18, 27, 30, 35,\n",
      "        19, 39,  0, 30, 35, 34, 33, 24, 19, 20,  3,  8,  0, 23, 16, 34, 20,  0,\n",
      "        23, 30, 37,  0, 34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35,\n",
      "        34,  3, 14, 30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,\n",
      "         3,  8, 34,  0, 32, 35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30, 27,\n",
      "        20,  0, 19, 16, 39,  3,  9, 35, 33, 34,  0, 21, 24, 29, 24, 33, 23, 20,\n",
      "        19,  0, 32, 20, 16, 19, 24, 29, 22,  0, 34, 23, 20,  0, 16, 32, 34, 24,\n",
      "        18, 27, 20,  3, 14, 23, 20,  0, 20, 36])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(all_text),dtype=torch.long)\n",
    "print(data.shape,data.dtype)\n",
    "print(data[:1000])# 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a860f",
   "metadata": {
    "papermill": {
     "duration": 0.003241,
     "end_time": "2025-04-24T16:29:39.110916",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.107675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* split data into train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cec34d30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:39.119815Z",
     "iopub.status.busy": "2025-04-24T16:29:39.118882Z",
     "iopub.status.idle": "2025-04-24T16:29:39.123484Z",
     "shell.execute_reply": "2025-04-24T16:29:39.122642Z"
    },
    "papermill": {
     "duration": 0.010328,
     "end_time": "2025-04-24T16:29:39.124818",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.114490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be268ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:39.132937Z",
     "iopub.status.busy": "2025-04-24T16:29:39.132662Z",
     "iopub.status.idle": "2025-04-24T16:29:39.138944Z",
     "shell.execute_reply": "2025-04-24T16:29:39.138243Z"
    },
    "papermill": {
     "duration": 0.011953,
     "end_time": "2025-04-24T16:29:39.140328",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.128375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 23, 20,  0, 20, 36, 20, 29, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4824934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:39.148644Z",
     "iopub.status.busy": "2025-04-24T16:29:39.148344Z",
     "iopub.status.idle": "2025-04-24T16:29:39.157882Z",
     "shell.execute_reply": "2025-04-24T16:29:39.156735Z"
    },
    "papermill": {
     "duration": 0.015513,
     "end_time": "2025-04-24T16:29:39.159429",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.143916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([14]) the target:23\n",
      "when input is tensor([14, 23]) the target:20\n",
      "when input is tensor([14, 23, 20]) the target:0\n",
      "when input is tensor([14, 23, 20,  0]) the target:20\n",
      "when input is tensor([14, 23, 20,  0, 20]) the target:36\n",
      "when input is tensor([14, 23, 20,  0, 20, 36]) the target:20\n",
      "when input is tensor([14, 23, 20,  0, 20, 36, 20]) the target:29\n",
      "when input is tensor([14, 23, 20,  0, 20, 36, 20, 29]) the target:34\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target:{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc09a03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:39.168185Z",
     "iopub.status.busy": "2025-04-24T16:29:39.167861Z",
     "iopub.status.idle": "2025-04-24T16:29:39.204110Z",
     "shell.execute_reply": "2025-04-24T16:29:39.202868Z"
    },
    "papermill": {
     "duration": 0.042302,
     "end_time": "2025-04-24T16:29:39.205619",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.163317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 8,  2, 28,  0, 33, 30,  0, 23],\n",
      "        [33,  0, 14, 35, 20, 33, 19, 16],\n",
      "        [24, 18,  0, 20, 38, 31, 20, 32],\n",
      "        [34,  0, 16,  0, 37, 30, 29, 19]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2, 28,  0, 33, 30,  0, 23, 16],\n",
      "        [ 0, 14, 35, 20, 33, 19, 16, 39],\n",
      "        [18,  0, 20, 38, 31, 20, 32, 24],\n",
      "        [ 0, 16,  0, 37, 30, 29, 19, 20]])\n",
      "-----\n",
      "when input is [8] the target: 2\n",
      "when input is [8, 2] the target: 28\n",
      "when input is [8, 2, 28] the target: 0\n",
      "when input is [8, 2, 28, 0] the target: 33\n",
      "when input is [8, 2, 28, 0, 33] the target: 30\n",
      "when input is [8, 2, 28, 0, 33, 30] the target: 0\n",
      "when input is [8, 2, 28, 0, 33, 30, 0] the target: 23\n",
      "when input is [8, 2, 28, 0, 33, 30, 0, 23] the target: 16\n",
      "when input is [33] the target: 0\n",
      "when input is [33, 0] the target: 14\n",
      "when input is [33, 0, 14] the target: 35\n",
      "when input is [33, 0, 14, 35] the target: 20\n",
      "when input is [33, 0, 14, 35, 20] the target: 33\n",
      "when input is [33, 0, 14, 35, 20, 33] the target: 19\n",
      "when input is [33, 0, 14, 35, 20, 33, 19] the target: 16\n",
      "when input is [33, 0, 14, 35, 20, 33, 19, 16] the target: 39\n",
      "when input is [24] the target: 18\n",
      "when input is [24, 18] the target: 0\n",
      "when input is [24, 18, 0] the target: 20\n",
      "when input is [24, 18, 0, 20] the target: 38\n",
      "when input is [24, 18, 0, 20, 38] the target: 31\n",
      "when input is [24, 18, 0, 20, 38, 31] the target: 20\n",
      "when input is [24, 18, 0, 20, 38, 31, 20] the target: 32\n",
      "when input is [24, 18, 0, 20, 38, 31, 20, 32] the target: 24\n",
      "when input is [34] the target: 0\n",
      "when input is [34, 0] the target: 16\n",
      "when input is [34, 0, 16] the target: 0\n",
      "when input is [34, 0, 16, 0] the target: 37\n",
      "when input is [34, 0, 16, 0, 37] the target: 30\n",
      "when input is [34, 0, 16, 0, 37, 30] the target: 29\n",
      "when input is [34, 0, 16, 0, 37, 30, 29] the target: 19\n",
      "when input is [34, 0, 16, 0, 37, 30, 29, 19] the target: 20\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size]for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1]for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2cc494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T16:29:39.214309Z",
     "iopub.status.busy": "2025-04-24T16:29:39.213975Z",
     "iopub.status.idle": "2025-04-24T16:29:39.219704Z",
     "shell.execute_reply": "2025-04-24T16:29:39.218703Z"
    },
    "papermill": {
     "duration": 0.011497,
     "end_time": "2025-04-24T16:29:39.220980",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.209483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  2, 28,  0, 33, 30,  0, 23],\n",
      "        [33,  0, 14, 35, 20, 33, 19, 16],\n",
      "        [24, 18,  0, 20, 38, 31, 20, 32],\n",
      "        [34,  0, 16,  0, 37, 30, 29, 19]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # input to the transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cbc6fd",
   "metadata": {
    "papermill": {
     "duration": 0.003482,
     "end_time": "2025-04-24T16:29:39.228360",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.224878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Notebook is incmpoleted need to implemet more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458178e",
   "metadata": {
    "papermill": {
     "duration": 0.003455,
     "end_time": "2025-04-24T16:29:39.235428",
     "exception": false,
     "start_time": "2025-04-24T16:29:39.231973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7005568,
     "sourceId": 11218125,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.119374,
   "end_time": "2025-04-24T16:29:41.688754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-24T16:29:27.569380",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
