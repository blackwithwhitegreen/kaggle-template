{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9beea9bf",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:29.726707Z",
     "iopub.status.busy": "2025-05-10T15:44:29.726413Z",
     "iopub.status.idle": "2025-05-10T15:44:31.654347Z",
     "shell.execute_reply": "2025-05-10T15:44:31.653012Z"
    },
    "papermill": {
     "duration": 1.938079,
     "end_time": "2025-05-10T15:44:31.656066",
     "exception": false,
     "start_time": "2025-05-10T15:44:29.717987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tweet-sentiment-classification-dataset/tweet_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf9eeea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:31.672088Z",
     "iopub.status.busy": "2025-05-10T15:44:31.671008Z",
     "iopub.status.idle": "2025-05-10T15:44:31.712244Z",
     "shell.execute_reply": "2025-05-10T15:44:31.711025Z"
    },
    "papermill": {
     "duration": 0.05069,
     "end_time": "2025-05-10T15:44:31.713887",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.663197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The event starts at 5 PM.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I hate how this turned out.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fantastic experience!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is the worst thing ever!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>It’s cloudy outside.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Great job by the team!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I'm so happy about the news!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>It ruined my whole day.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>I'm sick of this happening.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweet sentiment\n",
       "0        The event starts at 5 PM.   neutral\n",
       "1      I hate how this turned out.  negative\n",
       "2            Fantastic experience!  positive\n",
       "3            Fantastic experience!  positive\n",
       "4    This is the worst thing ever!  negative\n",
       "..                             ...       ...\n",
       "995           It’s cloudy outside.   neutral\n",
       "996         Great job by the team!  positive\n",
       "997   I'm so happy about the news!  positive\n",
       "998        It ruined my whole day.  negative\n",
       "999    I'm sick of this happening.  negative\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/tweet-sentiment-classification-dataset/tweet_sentiment.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30d9bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:31.729841Z",
     "iopub.status.busy": "2025-05-10T15:44:31.729545Z",
     "iopub.status.idle": "2025-05-10T15:44:31.752178Z",
     "shell.execute_reply": "2025-05-10T15:44:31.751213Z"
    },
    "papermill": {
     "duration": 0.031463,
     "end_time": "2025-05-10T15:44:31.753719",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.722256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   tweet      1000 non-null   object\n",
      " 1   sentiment  1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec51565",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:31.768571Z",
     "iopub.status.busy": "2025-05-10T15:44:31.768141Z",
     "iopub.status.idle": "2025-05-10T15:44:31.780245Z",
     "shell.execute_reply": "2025-05-10T15:44:31.779127Z"
    },
    "papermill": {
     "duration": 0.023971,
     "end_time": "2025-05-10T15:44:31.784475",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.760504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Chars\n",
      " !'.5AFGIJMPRSTWabcdefghijklmnoprstuvwxy’\n",
      "\n",
      "Toatl unique charactes: 41\n"
     ]
    }
   ],
   "source": [
    "# all unique chars that occure in the tweet\n",
    "all_text = ''.join(df['tweet'].astype(str))\n",
    "chars = sorted(set(all_text))\n",
    "vocab_size=len(chars)\n",
    "print(\"Unique Chars\")\n",
    "print(''.join(chars))\n",
    "print('\\nToatl unique charactes:',len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bcc2d04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:31.807799Z",
     "iopub.status.busy": "2025-05-10T15:44:31.807489Z",
     "iopub.status.idle": "2025-05-10T15:44:31.813834Z",
     "shell.execute_reply": "2025-05-10T15:44:31.812738Z"
    },
    "papermill": {
     "duration": 0.020191,
     "end_time": "2025-05-10T15:44:31.815586",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.795395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 32, 20, 16, 34, 0, 25, 30, 17, 0, 17, 39, 0, 34, 23, 20, 0, 34, 20, 16, 28, 1]\n",
      "Great job by the team!\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping from chars to integere\n",
    "map1 = { ch:i for i,ch in enumerate(chars) }\n",
    "map2 = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "encode = lambda s: [map1[c] for c in s]# encoder: take a string, output a list of integers.\n",
    "decode = lambda l: ''.join([map2[i] for i in l])# decoder: take a list of integers, output a string\n",
    "\n",
    "print(encode(\"Great job by the team!\"))\n",
    "print(decode(encode(\"Great job by the team!\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25407aeb",
   "metadata": {
    "papermill": {
     "duration": 0.006498,
     "end_time": "2025-05-10T15:44:31.833457",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.826959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Let's now encode the entire text dataset and store it into a torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9681672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:31.848149Z",
     "iopub.status.busy": "2025-05-10T15:44:31.847748Z",
     "iopub.status.idle": "2025-05-10T15:44:36.348540Z",
     "shell.execute_reply": "2025-05-10T15:44:36.347155Z"
    },
    "papermill": {
     "duration": 4.510052,
     "end_time": "2025-05-10T15:44:36.350119",
     "exception": false,
     "start_time": "2025-05-10T15:44:31.840067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24608]) torch.int64\n",
      "tensor([14, 23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16,\n",
      "        34,  0,  4,  0, 11, 10,  3,  8,  0, 23, 16, 34, 20,  0, 23, 30, 37,  0,\n",
      "        34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35, 34,  3,  6, 16,\n",
      "        29, 34, 16, 33, 34, 24, 18,  0, 20, 38, 31, 20, 32, 24, 20, 29, 18, 20,\n",
      "         1,  6, 16, 29, 34, 16, 33, 34, 24, 18,  0, 20, 38, 31, 20, 32, 24, 20,\n",
      "        29, 18, 20,  1, 14, 23, 24, 33,  0, 24, 33,  0, 34, 23, 20,  0, 37, 30,\n",
      "        32, 33, 34,  0, 34, 23, 24, 29, 22,  0, 20, 36, 20, 32,  1, 14, 23, 20,\n",
      "         0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16, 34,  0,  4,\n",
      "         0, 11, 10,  3, 15, 23, 16, 34,  0, 16,  0, 37, 30, 29, 19, 20, 32, 21,\n",
      "        35, 27,  0, 19, 16, 39,  1,  7, 32, 20, 16, 34,  0, 25, 30, 17,  0, 17,\n",
      "        39,  0, 34, 23, 20,  0, 34, 20, 16, 28,  1, 15, 23, 16, 34,  0, 16,  0,\n",
      "        37, 30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16, 39,  1,  8, 34,  0, 32,\n",
      "        35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30, 27, 20,  0, 19, 16, 39,\n",
      "         3,  9, 35, 33, 34,  0, 21, 24, 29, 24, 33, 23, 20, 19,  0, 32, 20, 16,\n",
      "        19, 24, 29, 22,  0, 34, 23, 20,  0, 16, 32, 34, 24, 18, 27, 20,  3, 14,\n",
      "        30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,  3, 14, 23,\n",
      "        24, 33,  0, 24, 33,  0, 34, 23, 20,  0, 37, 30, 32, 33, 34,  0, 34, 23,\n",
      "        24, 29, 22,  0, 20, 36, 20, 32,  1,  8,  0, 23, 16, 34, 20,  0, 23, 30,\n",
      "        37,  0, 34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35, 34,  3,\n",
      "        14, 30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,  3, 15,\n",
      "        23, 16, 34,  0, 16,  0, 37, 30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16,\n",
      "        39,  1, 12, 20, 16, 27, 27, 39,  0, 19, 24, 33, 16, 31, 31, 30, 24, 29,\n",
      "        34, 20, 19,  0, 24, 29,  0, 34, 23, 20,  0, 32, 20, 33, 35, 27, 34, 33,\n",
      "         3,  8,  2, 28,  0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35,\n",
      "        34,  0, 34, 23, 20,  0, 29, 20, 37, 33,  1, 14, 23, 24, 33,  0, 35, 31,\n",
      "        19, 16, 34, 20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1, 14,\n",
      "        23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34, 33,  0, 16, 34,\n",
      "         0,  4,  0, 11, 10,  3,  8,  2, 28,  0, 33, 24, 18, 26,  0, 30, 21,  0,\n",
      "        34, 23, 24, 33,  0, 23, 16, 31, 31, 20, 29, 24, 29, 22,  3,  8,  2, 28,\n",
      "         0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35, 34,  0, 34, 23,\n",
      "        20,  0, 29, 20, 37, 33,  1, 14, 23, 24, 33,  0, 35, 31, 19, 16, 34, 20,\n",
      "         0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1,  8,  2, 28,  0, 33,\n",
      "        24, 18, 26,  0, 30, 21,  0, 34, 23, 24, 33,  0, 23, 16, 31, 31, 20, 29,\n",
      "        24, 29, 22,  3, 12, 20, 16, 27, 27, 39,  0, 19, 24, 33, 16, 31, 31, 30,\n",
      "        24, 29, 34, 20, 19,  0, 24, 29,  0, 34, 23, 20,  0, 32, 20, 33, 35, 27,\n",
      "        34, 33,  3, 14, 23, 20,  0, 20, 36, 20, 29, 34,  0, 33, 34, 16, 32, 34,\n",
      "        33,  0, 16, 34,  0,  4,  0, 11, 10,  3, 15, 23, 16, 34,  0, 16,  0, 37,\n",
      "        30, 29, 19, 20, 32, 21, 35, 27,  0, 19, 16, 39,  1, 14, 23, 24, 33,  0,\n",
      "        24, 33,  0, 34, 23, 20,  0, 37, 30, 32, 33, 34,  0, 34, 23, 24, 29, 22,\n",
      "         0, 20, 36, 20, 32,  1, 14, 23, 24, 33,  0, 24, 33,  0, 34, 23, 20,  0,\n",
      "        37, 30, 32, 33, 34,  0, 34, 23, 24, 29, 22,  0, 20, 36, 20, 32,  1,  8,\n",
      "         2, 28,  0, 33, 30,  0, 23, 16, 31, 31, 39,  0, 16, 17, 30, 35, 34,  0,\n",
      "        34, 23, 20,  0, 29, 20, 37, 33,  1, 14, 30, 19, 16, 39,  0, 24, 33,  0,\n",
      "        14, 35, 20, 33, 19, 16, 39,  3, 14, 23, 24, 33,  0, 35, 31, 19, 16, 34,\n",
      "        20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16, 39,  1, 14, 23, 24, 33,\n",
      "         0, 35, 31, 19, 16, 34, 20,  0, 28, 16, 19, 20,  0, 28, 39,  0, 19, 16,\n",
      "        39,  1,  8, 34,  0, 32, 35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30,\n",
      "        27, 20,  0, 19, 16, 39,  3,  8, 34, 40, 33,  0, 18, 27, 30, 35, 19, 39,\n",
      "         0, 30, 35, 34, 33, 24, 19, 20,  3,  8, 34, 40, 33,  0, 18, 27, 30, 35,\n",
      "        19, 39,  0, 30, 35, 34, 33, 24, 19, 20,  3,  8,  0, 23, 16, 34, 20,  0,\n",
      "        23, 30, 37,  0, 34, 23, 24, 33,  0, 34, 35, 32, 29, 20, 19,  0, 30, 35,\n",
      "        34,  3, 14, 30, 19, 16, 39,  0, 24, 33,  0, 14, 35, 20, 33, 19, 16, 39,\n",
      "         3,  8, 34,  0, 32, 35, 24, 29, 20, 19,  0, 28, 39,  0, 37, 23, 30, 27,\n",
      "        20,  0, 19, 16, 39,  3,  9, 35, 33, 34,  0, 21, 24, 29, 24, 33, 23, 20,\n",
      "        19,  0, 32, 20, 16, 19, 24, 29, 22,  0, 34, 23, 20,  0, 16, 32, 34, 24,\n",
      "        18, 27, 20,  3, 14, 23, 20,  0, 20, 36])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(all_text),dtype=torch.long)\n",
    "print(data.shape,data.dtype)\n",
    "print(data[:1000])# 1000 characters we looked at earier will to the GPT look like this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf03094",
   "metadata": {
    "papermill": {
     "duration": 0.006324,
     "end_time": "2025-05-10T15:44:36.363294",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.356970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* split data into train and val sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7633c454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.377746Z",
     "iopub.status.busy": "2025-05-10T15:44:36.377320Z",
     "iopub.status.idle": "2025-05-10T15:44:36.382047Z",
     "shell.execute_reply": "2025-05-10T15:44:36.381218Z"
    },
    "papermill": {
     "duration": 0.013931,
     "end_time": "2025-05-10T15:44:36.383720",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.369789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83da07c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.398708Z",
     "iopub.status.busy": "2025-05-10T15:44:36.398004Z",
     "iopub.status.idle": "2025-05-10T15:44:36.405028Z",
     "shell.execute_reply": "2025-05-10T15:44:36.404208Z"
    },
    "papermill": {
     "duration": 0.015791,
     "end_time": "2025-05-10T15:44:36.406302",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.390511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 23, 20,  0, 20, 36, 20, 29, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131ae181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.422014Z",
     "iopub.status.busy": "2025-05-10T15:44:36.421132Z",
     "iopub.status.idle": "2025-05-10T15:44:36.430248Z",
     "shell.execute_reply": "2025-05-10T15:44:36.429310Z"
    },
    "papermill": {
     "duration": 0.018743,
     "end_time": "2025-05-10T15:44:36.431901",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.413158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([14]) the target:23\n",
      "when input is tensor([14, 23]) the target:20\n",
      "when input is tensor([14, 23, 20]) the target:0\n",
      "when input is tensor([14, 23, 20,  0]) the target:20\n",
      "when input is tensor([14, 23, 20,  0, 20]) the target:36\n",
      "when input is tensor([14, 23, 20,  0, 20, 36]) the target:20\n",
      "when input is tensor([14, 23, 20,  0, 20, 36, 20]) the target:29\n",
      "when input is tensor([14, 23, 20,  0, 20, 36, 20, 29]) the target:34\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target:{target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99f918a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.447076Z",
     "iopub.status.busy": "2025-05-10T15:44:36.446798Z",
     "iopub.status.idle": "2025-05-10T15:44:36.482123Z",
     "shell.execute_reply": "2025-05-10T15:44:36.481034Z"
    },
    "papermill": {
     "duration": 0.045019,
     "end_time": "2025-05-10T15:44:36.483769",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.438750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 8,  2, 28,  0, 33, 30,  0, 23],\n",
      "        [33,  0, 14, 35, 20, 33, 19, 16],\n",
      "        [24, 18,  0, 20, 38, 31, 20, 32],\n",
      "        [34,  0, 16,  0, 37, 30, 29, 19]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 2, 28,  0, 33, 30,  0, 23, 16],\n",
      "        [ 0, 14, 35, 20, 33, 19, 16, 39],\n",
      "        [18,  0, 20, 38, 31, 20, 32, 24],\n",
      "        [ 0, 16,  0, 37, 30, 29, 19, 20]])\n",
      "-----\n",
      "when input is [8] the target: 2\n",
      "when input is [8, 2] the target: 28\n",
      "when input is [8, 2, 28] the target: 0\n",
      "when input is [8, 2, 28, 0] the target: 33\n",
      "when input is [8, 2, 28, 0, 33] the target: 30\n",
      "when input is [8, 2, 28, 0, 33, 30] the target: 0\n",
      "when input is [8, 2, 28, 0, 33, 30, 0] the target: 23\n",
      "when input is [8, 2, 28, 0, 33, 30, 0, 23] the target: 16\n",
      "when input is [33] the target: 0\n",
      "when input is [33, 0] the target: 14\n",
      "when input is [33, 0, 14] the target: 35\n",
      "when input is [33, 0, 14, 35] the target: 20\n",
      "when input is [33, 0, 14, 35, 20] the target: 33\n",
      "when input is [33, 0, 14, 35, 20, 33] the target: 19\n",
      "when input is [33, 0, 14, 35, 20, 33, 19] the target: 16\n",
      "when input is [33, 0, 14, 35, 20, 33, 19, 16] the target: 39\n",
      "when input is [24] the target: 18\n",
      "when input is [24, 18] the target: 0\n",
      "when input is [24, 18, 0] the target: 20\n",
      "when input is [24, 18, 0, 20] the target: 38\n",
      "when input is [24, 18, 0, 20, 38] the target: 31\n",
      "when input is [24, 18, 0, 20, 38, 31] the target: 20\n",
      "when input is [24, 18, 0, 20, 38, 31, 20] the target: 32\n",
      "when input is [24, 18, 0, 20, 38, 31, 20, 32] the target: 24\n",
      "when input is [34] the target: 0\n",
      "when input is [34, 0] the target: 16\n",
      "when input is [34, 0, 16] the target: 0\n",
      "when input is [34, 0, 16, 0] the target: 37\n",
      "when input is [34, 0, 16, 0, 37] the target: 30\n",
      "when input is [34, 0, 16, 0, 37, 30] the target: 29\n",
      "when input is [34, 0, 16, 0, 37, 30, 29] the target: 19\n",
      "when input is [34, 0, 16, 0, 37, 30, 29, 19] the target: 20\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size]for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1]for i in ix])\n",
    "    return x,y\n",
    "\n",
    "xb,yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('-----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b,:t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f\"when input is {context.tolist()} the target: {target}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c195606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.499683Z",
     "iopub.status.busy": "2025-05-10T15:44:36.498784Z",
     "iopub.status.idle": "2025-05-10T15:44:36.504736Z",
     "shell.execute_reply": "2025-05-10T15:44:36.503634Z"
    },
    "papermill": {
     "duration": 0.015335,
     "end_time": "2025-05-10T15:44:36.506288",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.490953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8,  2, 28,  0, 33, 30,  0, 23],\n",
      "        [33,  0, 14, 35, 20, 33, 19, 16],\n",
      "        [24, 18,  0, 20, 38, 31, 20, 32],\n",
      "        [34,  0, 16,  0, 37, 30, 29, 19]])\n"
     ]
    }
   ],
   "source": [
    "print(xb) # input to the transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f2947b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.521481Z",
     "iopub.status.busy": "2025-05-10T15:44:36.521155Z",
     "iopub.status.idle": "2025-05-10T15:44:36.618206Z",
     "shell.execute_reply": "2025-05-10T15:44:36.616997Z"
    },
    "papermill": {
     "duration": 0.106262,
     "end_time": "2025-05-10T15:44:36.619699",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.513437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 41])\n",
      "tensor(3.9208, grad_fn=<NllLossBackward0>)\n",
      " tvgRiRvMifG'lgJ'GaMijr!GvynliulmScPPxRgMPr!Sjjdeolbkp'ueAR FsrdmSt dSusa'l aW!exh fswwwwSjMu’tiSfjdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BiagramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "        ##\n",
    "        # self.position_embeddings_table = nn.Embedding(block_size,n_embd)\n",
    "        # self.blocks = nn.Sequential(*[Block(n_embd,n_head=n_head)for _ in range(n_layer)])\n",
    "        # self.ln_f = nn.LayerNorm(n_embd) # final Layer norm\n",
    "        # self.lm_head = nn.Linear(n_embd,vocab_size)\n",
    "        ##\n",
    "\n",
    "    def forward(self,idx,targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        ##\n",
    "        # B,T = idx.shape\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx)\n",
    "            logits = logits[:,-1,:]\n",
    "            prob = F.softmax(logits,dim=-1)\n",
    "\n",
    "            idx_next = torch.multinomial(prob,num_samples=1)\n",
    "            idx = torch.cat((idx,idx_next),dim=1)\n",
    "\n",
    "        return idx\n",
    "\n",
    "\n",
    "m = BiagramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "\n",
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype=torch.long),max_new_tokens=100)[0].tolist()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2566bf83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:36.635041Z",
     "iopub.status.busy": "2025-05-10T15:44:36.634747Z",
     "iopub.status.idle": "2025-05-10T15:44:42.118605Z",
     "shell.execute_reply": "2025-05-10T15:44:42.117724Z"
    },
    "papermill": {
     "duration": 5.493498,
     "end_time": "2025-05-10T15:44:42.120318",
     "exception": false,
     "start_time": "2025-05-10T15:44:36.626820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Pytorch Optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(),lr= 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fe8ba14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.136898Z",
     "iopub.status.busy": "2025-05-10T15:44:42.136026Z",
     "iopub.status.idle": "2025-05-10T15:44:42.344814Z",
     "shell.execute_reply": "2025-05-10T15:44:42.343717Z"
    },
    "papermill": {
     "duration": 0.218293,
     "end_time": "2025-05-10T15:44:42.346389",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.128096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.859891176223755\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(100):\n",
    "    xb,yb = get_batch('train')\n",
    "    \n",
    "    #evaluate the loss\n",
    "    logits,loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e67f79d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.362426Z",
     "iopub.status.busy": "2025-05-10T15:44:42.362102Z",
     "iopub.status.idle": "2025-05-10T15:44:42.435940Z",
     "shell.execute_reply": "2025-05-10T15:44:42.435007Z"
    },
    "papermill": {
     "duration": 0.083593,
     "end_time": "2025-05-10T15:44:42.437799",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.354206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " r5GbTkTjooiknWTFy’MvcS.yFFayjvMPskv'aopig’sT’R.Fywwx5W!ouhaJefellleWTfayvyxiSmkyaAyWsTvA'iTgrpIWTf.lmSueoisp aJPsW!R’5IucbSuWRaMuAiTJd.’JWg5P5eWvcolkJIScJIvgW!WkkJTlInhIpRhWPbydWjiSv’ RxjRiGhejv'lcr’RiPRxfuJutabvMPcllc cwW!JlknA5dproW’ltWWTfertSW!W!fIMPwr!rjdgW!vylcadmsbvIMAR’vgeuJwveStmov'feFgrk'kMFSuedyp WTfpichTfbGyr pluipiyxjp'p tf’uwwrAJb’v!RT’'bpmoiSuSTxnleIvtSj’JS’y5jovvFtPcwM!W’PMokFlAMf pvPnhihe!AJFavrgrwc plvtaJP’ tiyjMoWltMPSjovk!wwPa.’tS'xRgrcW!ScnIkJ!Sfs!!JyuG5Auwpt.p F IPgxmRiWl!FM\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1,1),dtype = torch.long),max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb062e",
   "metadata": {
    "papermill": {
     "duration": 0.006851,
     "end_time": "2025-05-10T15:44:42.451936",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.445085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d0a792f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.467233Z",
     "iopub.status.busy": "2025-05-10T15:44:42.466904Z",
     "iopub.status.idle": "2025-05-10T15:44:42.500434Z",
     "shell.execute_reply": "2025-05-10T15:44:42.499392Z"
    },
    "papermill": {
     "duration": 0.042957,
     "end_time": "2025-05-10T15:44:42.501875",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.458918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a/torch.sum(a,1,keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('b=')\n",
    "print(b)\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea3973b",
   "metadata": {
    "papermill": {
     "duration": 0.007493,
     "end_time": "2025-05-10T15:44:42.516592",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.509099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Consider the following toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebd36d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.532217Z",
     "iopub.status.busy": "2025-05-10T15:44:42.531876Z",
     "iopub.status.idle": "2025-05-10T15:44:42.539882Z",
     "shell.execute_reply": "2025-05-10T15:44:42.539040Z"
    },
    "papermill": {
     "duration": 0.017636,
     "end_time": "2025-05-10T15:44:42.541352",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.523716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,2 #batch,time,channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42dbf674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.557140Z",
     "iopub.status.busy": "2025-05-10T15:44:42.556841Z",
     "iopub.status.idle": "2025-05-10T15:44:42.563883Z",
     "shell.execute_reply": "2025-05-10T15:44:42.562873Z"
    },
    "papermill": {
     "duration": 0.016822,
     "end_time": "2025-05-10T15:44:42.565589",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.548767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we want x[b,t] = mean_{i<=t} x[b,i]\n",
    "xbow = torch.zeros((B,T,C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1] #(t,c)\n",
    "        xbow[b,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d1027",
   "metadata": {
    "papermill": {
     "duration": 0.006996,
     "end_time": "2025-05-10T15:44:42.580416",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.573420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* version 2 using matrix multiply for a weighted aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592e2f9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.596340Z",
     "iopub.status.busy": "2025-05-10T15:44:42.595972Z",
     "iopub.status.idle": "2025-05-10T15:44:42.605865Z",
     "shell.execute_reply": "2025-05-10T15:44:42.605098Z"
    },
    "papermill": {
     "duration": 0.019673,
     "end_time": "2025-05-10T15:44:42.607408",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.587735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T,T))\n",
    "wei = wei / wei.sum(1,keepdim=True)\n",
    "xbow2 = wei @ x # (B,T,T) @ (B,T,C) -----> (B,T,C)\n",
    "torch.allclose(xbow,xbow2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af6291e",
   "metadata": {
    "papermill": {
     "duration": 0.007277,
     "end_time": "2025-05-10T15:44:42.622356",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.615079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* version 3 Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e36bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.638564Z",
     "iopub.status.busy": "2025-05-10T15:44:42.638271Z",
     "iopub.status.idle": "2025-05-10T15:44:42.658033Z",
     "shell.execute_reply": "2025-05-10T15:44:42.656961Z"
    },
    "papermill": {
     "duration": 0.030094,
     "end_time": "2025-05-10T15:44:42.659874",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.629780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 #batch,time,channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C,head_size,bias=False)\n",
    "query = nn.Linear(C,head_size,bias=False)\n",
    "value = nn.Linear(C,head_size,bias=False)\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "wei = q @ k.transpose(-2,-1)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0,float('-inf'))\n",
    "wei = F.softmax(wei,dim=1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1330222f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.677823Z",
     "iopub.status.busy": "2025-05-10T15:44:42.677507Z",
     "iopub.status.idle": "2025-05-10T15:44:42.684999Z",
     "shell.execute_reply": "2025-05-10T15:44:42.684117Z"
    },
    "papermill": {
     "duration": 0.017731,
     "end_time": "2025-05-10T15:44:42.686733",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.669002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0248, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0052, 0.0091, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0521, 0.0135, 0.2482, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3171, 0.0214, 0.1642, 0.1188, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0412, 0.0487, 0.1046, 0.0742, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1060, 0.5347, 0.2059, 0.1030, 0.7402, 0.0192, 0.0000, 0.0000],\n",
       "        [0.4298, 0.3409, 0.1769, 0.2027, 0.0480, 0.8472, 0.2329, 0.0000],\n",
       "        [0.0238, 0.0316, 0.1002, 0.5013, 0.0117, 0.1336, 0.7671, 1.0000]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ef4a92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.767219Z",
     "iopub.status.busy": "2025-05-10T15:44:42.766876Z",
     "iopub.status.idle": "2025-05-10T15:44:42.772440Z",
     "shell.execute_reply": "2025-05-10T15:44:42.771536Z"
    },
    "papermill": {
     "duration": 0.016106,
     "end_time": "2025-05-10T15:44:42.774257",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.758151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2,-1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7283fc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.792108Z",
     "iopub.status.busy": "2025-05-10T15:44:42.791255Z",
     "iopub.status.idle": "2025-05-10T15:44:42.797657Z",
     "shell.execute_reply": "2025-05-10T15:44:42.796924Z"
    },
    "papermill": {
     "duration": 0.016535,
     "end_time": "2025-05-10T15:44:42.798898",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.782363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64447ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.815733Z",
     "iopub.status.busy": "2025-05-10T15:44:42.815434Z",
     "iopub.status.idle": "2025-05-10T15:44:42.821607Z",
     "shell.execute_reply": "2025-05-10T15:44:42.820948Z"
    },
    "papermill": {
     "duration": 0.016232,
     "end_time": "2025-05-10T15:44:42.822925",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.806693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83979840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.840004Z",
     "iopub.status.busy": "2025-05-10T15:44:42.839460Z",
     "iopub.status.idle": "2025-05-10T15:44:42.845799Z",
     "shell.execute_reply": "2025-05-10T15:44:42.844936Z"
    },
    "papermill": {
     "duration": 0.016538,
     "end_time": "2025-05-10T15:44:42.847265",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.830727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd40d87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.864301Z",
     "iopub.status.busy": "2025-05-10T15:44:42.863969Z",
     "iopub.status.idle": "2025-05-10T15:44:42.870977Z",
     "shell.execute_reply": "2025-05-10T15:44:42.870189Z"
    },
    "papermill": {
     "duration": 0.017133,
     "end_time": "2025-05-10T15:44:42.872395",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.855262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5]),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c6d8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.889353Z",
     "iopub.status.busy": "2025-05-10T15:44:42.889027Z",
     "iopub.status.idle": "2025-05-10T15:44:42.895592Z",
     "shell.execute_reply": "2025-05-10T15:44:42.894865Z"
    },
    "papermill": {
     "duration": 0.016576,
     "end_time": "2025-05-10T15:44:42.896869",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.880293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1,-0.2,0.3,-0.2,0.5])*8,dim=-1) #gets too peaky,converge to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fb01cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.914407Z",
     "iopub.status.busy": "2025-05-10T15:44:42.914021Z",
     "iopub.status.idle": "2025-05-10T15:44:42.926637Z",
     "shell.execute_reply": "2025-05-10T15:44:42.925661Z"
    },
    "papermill": {
     "duration": 0.023414,
     "end_time": "2025-05-10T15:44:42.928241",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.904827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d:\n",
    "\n",
    "    def __init__(self,dim,eps=1e-5,nomentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self,x):\n",
    "        # calculate the forward pass\n",
    "        xmean = x.mean(1,keepdim=True) #batch mean\n",
    "        xvar = x.var(1,keepdim=True) # batch variance\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variacne\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma,self.beta]\n",
    "\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32,100) # barch size 32 of 100 dimensional vectors\n",
    "x = module(x)\n",
    "x.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0884af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.945458Z",
     "iopub.status.busy": "2025-05-10T15:44:42.945151Z",
     "iopub.status.idle": "2025-05-10T15:44:42.952185Z",
     "shell.execute_reply": "2025-05-10T15:44:42.951251Z"
    },
    "papermill": {
     "duration": 0.017307,
     "end_time": "2025-05-10T15:44:42.953690",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.936383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(),x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e215101a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.971720Z",
     "iopub.status.busy": "2025-05-10T15:44:42.971085Z",
     "iopub.status.idle": "2025-05-10T15:44:42.977633Z",
     "shell.execute_reply": "2025-05-10T15:44:42.976924Z"
    },
    "papermill": {
     "duration": 0.016775,
     "end_time": "2025-05-10T15:44:42.978869",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.962094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(),x[0,:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de0933e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T15:44:42.997125Z",
     "iopub.status.busy": "2025-05-10T15:44:42.996822Z",
     "iopub.status.idle": "2025-05-10T15:44:43.004422Z",
     "shell.execute_reply": "2025-05-10T15:44:43.003586Z"
    },
    "papermill": {
     "duration": 0.018489,
     "end_time": "2025-05-10T15:44:43.005761",
     "exception": false,
     "start_time": "2025-05-10T15:44:42.987272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.nn import functional as F\n",
    "\n",
    "# # hyperparameters\n",
    "# batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "# block_size = 32 # what is the maximum context length for predictions?\n",
    "# max_iters = 5000\n",
    "# eval_interval = 100\n",
    "# learning_rate = 1e-3\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# eval_iters = 200\n",
    "# n_embd = 64\n",
    "# n_head = 4\n",
    "# n_layer = 4\n",
    "# dropout = 0.0\n",
    "# # ------------\n",
    "\n",
    "# torch.manual_seed(1337)\n",
    "\n",
    "# # # wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "# # with open('/content/colab.txt', 'r', encoding='utf-8') as f:\n",
    "# #     text = f.read()\n",
    "\n",
    "\n",
    "# # all unique chars that occure in the tweet\n",
    "# all_text = ''.join(df['tweet'].astype(str))\n",
    "# chars = sorted(set(all_text))\n",
    "# vocab_size=len(chars)\n",
    "# print(\"Unique Chars\")\n",
    "# print(''.join(chars))\n",
    "# print('\\nToatl unique charactes:',len(chars))\n",
    "\n",
    "\n",
    "\n",
    "# # here are all the unique characters that occur in this text\n",
    "# # chars = sorted(list(set(text)))\n",
    "# # vocab_size = len(chars)\n",
    "# # # create a mapping from characters to integers\n",
    "# # stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "# # itos = { i:ch for i,ch in enumerate(chars) }\n",
    "# # encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "# # decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# # Train and test splits\n",
    "# data = torch.tensor(encode(text), dtype=torch.long)\n",
    "# n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "# train_data = data[:n]\n",
    "# val_data = data[n:]\n",
    "\n",
    "# # data loading\n",
    "# def get_batch(split):\n",
    "#     # generate a small batch of data of inputs x and targets y\n",
    "#     data = train_data if split == 'train' else val_data\n",
    "#     ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "#     x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "#     y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "#     x, y = x.to(device), y.to(device)\n",
    "#     return x, y\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def estimate_loss():\n",
    "#     out = {}\n",
    "#     model.eval()\n",
    "#     for split in ['train', 'val']:\n",
    "#         losses = torch.zeros(eval_iters)\n",
    "#         for k in range(eval_iters):\n",
    "#             X, Y = get_batch(split)\n",
    "#             logits, loss = model(X, Y)\n",
    "#             losses[k] = loss.item()\n",
    "#         out[split] = losses.mean()\n",
    "#     model.train()\n",
    "#     return out\n",
    "\n",
    "# class Head(nn.Module):\n",
    "#     \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "#     def __init__(self, head_size):\n",
    "#         super().__init__()\n",
    "#         self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "#         self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "#         self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "#         self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         B,T,C = x.shape\n",
    "#         k = self.key(x)   # (B,T,C)\n",
    "#         q = self.query(x) # (B,T,C)\n",
    "#         # compute attention scores (\"affinities\")\n",
    "#         wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "#         wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "#         wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "#         wei = self.dropout(wei)\n",
    "#         # perform the weighted aggregation of the values\n",
    "#         v = self.value(x) # (B,T,C)\n",
    "#         out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "#         return out\n",
    "\n",
    "# class MultiHeadAttention(nn.Module):\n",
    "#     \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "#     def __init__(self, num_heads, head_size):\n",
    "#         super().__init__()\n",
    "#         self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "#         self.proj = nn.Linear(n_embd, n_embd)\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "#         out = self.dropout(self.proj(out))\n",
    "#         return out\n",
    "\n",
    "# class FeedFoward(nn.Module):\n",
    "#     \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "#     def __init__(self, n_embd):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(n_embd, 4 * n_embd),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(4 * n_embd, n_embd),\n",
    "#             nn.Dropout(dropout),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# class Block(nn.Module):\n",
    "#     \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "#     def __init__(self, n_embd, n_head):\n",
    "#         # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "#         super().__init__()\n",
    "#         head_size = n_embd // n_head\n",
    "#         self.sa = MultiHeadAttention(n_head, head_size)\n",
    "#         self.ffwd = FeedFoward(n_embd)\n",
    "#         self.ln1 = nn.LayerNorm(n_embd)\n",
    "#         self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x + self.sa(self.ln1(x))\n",
    "#         x = x + self.ffwd(self.ln2(x))\n",
    "#         return x\n",
    "\n",
    "# # super simple bigram model\n",
    "# class BigramLanguageModel(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # each token directly reads off the logits for the next token from a lookup table\n",
    "#         self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "#         self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "#         self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "#         self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "#         self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "#     def forward(self, idx, targets=None):\n",
    "#         B, T = idx.shape\n",
    "\n",
    "#         # idx and targets are both (B,T) tensor of integers\n",
    "#         tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "#         pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "#         x = tok_emb + pos_emb # (B,T,C)\n",
    "#         x = self.blocks(x) # (B,T,C)\n",
    "#         x = self.ln_f(x) # (B,T,C)\n",
    "#         logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "#         if targets is None:\n",
    "#             loss = None\n",
    "#         else:\n",
    "#             B, T, C = logits.shape\n",
    "#             logits = logits.view(B*T, C)\n",
    "#             targets = targets.view(B*T)\n",
    "#             loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "#         return logits, loss\n",
    "\n",
    "#     def generate(self, idx, max_new_tokens):\n",
    "#         # idx is (B, T) array of indices in the current context\n",
    "#         for _ in range(max_new_tokens):\n",
    "#             # crop idx to the last block_size tokens\n",
    "#             idx_cond = idx[:, -block_size:]\n",
    "#             # get the predictions\n",
    "#             logits, loss = self(idx_cond)\n",
    "#             # focus only on the last time step\n",
    "#             logits = logits[:, -1, :] # becomes (B, C)\n",
    "#             # apply softmax to get probabilities\n",
    "#             probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "#             # sample from the distribution\n",
    "#             idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "#             # append sampled index to the running sequence\n",
    "#             idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "#         return idx\n",
    "\n",
    "# model = BigramLanguageModel()\n",
    "# m = model.to(device)\n",
    "# # print the number of parameters in the model\n",
    "# print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "# # create a PyTorch optimizer\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# for iter in range(max_iters):\n",
    "\n",
    "#     # every once in a while evaluate the loss on train and val sets\n",
    "#     if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "#         losses = estimate_loss()\n",
    "#         print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "#     # sample a batch of data\n",
    "#     xb, yb = get_batch('train')\n",
    "\n",
    "#     # evaluate the loss\n",
    "#     logits, loss = model(xb, yb)\n",
    "#     optimizer.zero_grad(set_to_none=True)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "# # generate from the model\n",
    "# context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "# print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df229ba",
   "metadata": {
    "papermill": {
     "duration": 0.008049,
     "end_time": "2025-05-10T15:44:43.022027",
     "exception": false,
     "start_time": "2025-05-10T15:44:43.013978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7005568,
     "sourceId": 11218125,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.123065,
   "end_time": "2025-05-10T15:44:46.148790",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-10T15:44:25.025725",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
